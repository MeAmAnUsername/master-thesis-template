% !TEX root = document.tex

\section{Problem analysis}
\label{sec:problem_analysis}

\todo{search and replace "PIE" with \\ac\{PIE\} and the same for DSL}

TODO: In this chapter:
\begin{itemize}
  \item Use case: Spoofax pipelines
  \begin{itemize}
    \item What is language development?
    \item What is Spoofax? (also explains the Spoofax Ecosystem, e.g. SDF3, NaBL2, Statix, Stratego)
    \item What are pipelines that we want to express with the PIE DSL?
  \end{itemize}
  \item More detailed explanations of the problems
\end{itemize}

PIE framework exists and is in active development.
It is implemented in Java so there is lots of boilerplate.

To resolve this, the PIE DSL avoids the boilerplate and adds language support for domain specific elements, e.g. paths, list comprehensions.
It still has room for improvement:
\begin{enumerate}
  \item cannot compile to Java
  \item cannot generate tasks with a dependency on something other than a task
  \item cannot compose PIE files
  \item cannot interface with Java generic classes
\end{enumerate}
\todo{write chapter}

\todo{use case. Summary: we want to run a pipeline in Spoofax, but we don't want to specify persistence and incrementality ad-hoc. This is what build systems do, but none of them are expressive and support precise dynamic dependencies}

\Ac{PIE} is a build system that aims to allow expressing pipelines with dynamic dependencies with automatic persistence and incremental execution.
It achieves this by being imperative rather than declarative: tasks can call other tasks.
\Ac{PIE} consists of the PIE framework and the \ac{PIE} \ac{DSL}.
The framework is an implementation of \ac{PIE} in Java.
The \ac{DSL} is a language developed to create a concise specification of pipelines.
The user can specify pipelines as functions that call each other.
This \ac{PIE} \ac{DSL} code is then compiled to definitions in the Java framework by the \ac{PIE} compiler.
The Java framework saves the inputs and corresponding outputs of tasks.
If a task is called with inputs that are cached, the corresponding output is returned without executing the task.

The Java framework keeps track of the task and file dependencies of tasks.
When a file changes, it can use the dependency graph to keep track of things.

\todo{Set editor to US English}



Language engineering is the discipline of designing and implementing programming languages.
Spoofax is a language workbench, i.e.\ an IDE for designing and implementing programming languages.
It brings tools that exist in regular software development to language engineering, like syntax highlighting, static analysis and a testing framework.
It allows a language developer to work on the specification of a language and have example programs of that language open at the same time.
This allows the language developer to get immediate feedback on their changes.
Spoofax will compile the language specification and parse and analyze the example programs, which allows the language developer to experiment with language features.
The goal of Spoofax is to abstract over the implementation details of implementing a language.
A language developer only has to declaratively specify the language, Spoofax will generate an implementation for a parser, static analyzer, syntax highlighting and other editor tools.

Generating these implementations uses a combination of external binary programs and Java functions.
These programs and functions have dependencies on files and each other's outputs.
This means that they form pipelines.
Because Spoofax is an IDE, we would like it to give quick feedback when a language developer makes small changes to the code.
However, executing the entire pipeline is really slow (in the order of minutes).
This means that executing the entire pipeline is not an option.
Instead, results are cached and recomputed when the output changes; this is called incrementality.
In the beginning, this was done ad-hoc: every program and Java function would have its own implementation for incrementality and persistence \todo{explain persistence before here}.
This turned out to be hard to maintain: caching is already colloquially known to be one of the "fundamental problems of computer science", so reinventing the wheel each time leads to a lot of bugs.

The problem of incrementally executing programs and functions in the right order already has a solution: a build system.
Unfortunately, existing build systems did not have all features required for Spoofax pipelines.
In particular, many build systems do not support dynamic dependencies.
Dynamic dependencies are dependencies that are not known until runtime.
A well known example are C header files: it is impossible to know what header files a particular C file depends on until you parse it.
The common solution is to overapproximate the dependency: make each C file depend on \emph{every} header file.
While this makes sure that every change is picked up on by the build system, it also means that every time a header file is changed, \emph{all} C files are considered out of date, even if few or even none of those C files depend on that particular header.

To solve this, dependencies should be precise: by keeping precise track of dependencies for every task





The Spoofax ecosystem includes several DSLs, like SDF3 to specify the grammar of a language, NaBL2 and Statix to specify the static semantics, and Stratego to specify program transformations. \todo{Can I assume that readers are familiar with language engineering in general? (i.e. they don't know Spoofax, but they do know what grammar, static semantics etc. are)}
The specifications in these DSLs are combined into a language specification.
This language specification is used by Spoofax to update open editors of the user language by parsing, analyzing, syntax highlighting and showing errors.
It can also be packaged into a plugin that does these things so that the user language can be used independently from Spoofax.

All of these tasks have dependencies on the specification files, other files, each other and other tasks.
Executing all tasks each time anything changes takes too long and is often not necessary: if an example program is updated, the language specification stays the same, so the language does not need to be rebuild.
Only the editor for that example program (and possibly other editors if they depend on this one) need to be re-parsed and re-analyzed.
The solution is incrementality: only execute the tasks with changed inputs.
If the input stays the same, return the output from cache.

Additionally, we don't want to rebuild the language each time we restart the IDE.


\Ac{PIE} is a build system that aims to allow expressing pipelines with dynamic dependencies with automatic persistence and incremental execution.
It achieves this by being imperative rather than declarative: tasks can call other tasks.
\Ac{PIE} consists of the PIE framework and the \ac{PIE} \ac{DSL}.
The framework is an implementation of \ac{PIE} in Java.
The \ac{DSL} is a language developed to create a concise specification of pipelines.
The user can specify pipelines as functions that call each other.
This \ac{PIE} \ac{DSL} code is then compiled to definitions in the Java framework by the \ac{PIE} compiler.
The Java framework saves the inputs and corresponding outputs of tasks.
If a task is called with inputs that are cached, the corresponding output is returned without executing the task.

The Java framework keeps track of the task and file dependencies of tasks.
When a file changes, it can use the dependency graph to keep track of things.

The PIE DSL is a language for expressing pipelines.
Pipelines are expressed as functions that call other functions.
While the DSL and the compiler did work, they also had several shortcomings:
\begin{enumerate}
  \item Existing compilers were not maintainable.
  \item Does not scale to larger projects, e.g. projects that consist of multiple language projects.
  \item Implemented in NaBL2, which has a few limitations in expressiveness.
  \item Limitations in expressiveness of the PIE DSL.
  \begin{enumerate}
    \item No way to express core concepts of PIE, e.g. Suppliers and Results.
    \item No way to declare injected values for tasks.
  \end{enumerate}
\end{enumerate}



\subsection{Background information}
\label{subsec:problem_analysis__background}

\todo{Explain:
- how are ASTs represented in Spoofax?
- compilation by string interpolation?
- Spoofax project setups: what are language projects?
- compilation with Stratego
- PIE DSL: foreign imports
- why can't PIE DSL interoperate with generic classes?
}

\subsubsection{ATerms}
\label{subsubsec:problem_analysis__background__aterms}

Programs are expressed in human readable syntax, but this is hard and inefficient to manipulate directly.
Instead, code is parsed to an AST, which throws away the syntax and keeps the parts of a program that can change.
In Spoofax, these ASTs are represented using ATerms.
An ATerm consists of a constructor, arguments and possibly some annotations.
As an example, the expression \inlinecode{x * 9 - 3} is represented as \inlinecode{Minus(Times(Var("x"), Int("9")), Int("3"))}.
Spoofax meta-languages can pattern-match on these constructors to define rules, such as rules in Stratego to transform a constructor or rules in Statix to define the static semantics.

\subsubsection{Ways to compile}
\label{subsubsec:problem_analysis__background__ways_to_compile}

There are two ways to compile from a source language to a target language.

The simplest way to compile a source language to a target language is to compile fragments of the source language into fragments of the target language, write a template in the target language and insert the compiled fragments into that template.
This method is called string interpolation.
It has the advantage of being fairly easy to read and write, but it has several disadvantages.
A major disadvantage of string compilation is that it does not have static checks.
This means that the Stratego compiler \todo{general term for "compiler compiler"} does not check that the generated code will form a correct program, or even that it is syntactically correct.
A simple typo in the generated code is only caught at runtime instead of compile time.
This leads to longer development times and transformation rules that are tested on a small subset of possible inputs, instead of verified for all possible inputs.
String interpolation is also inefficient in case one wants to do some post-processing on the generated code, such as performing optimizations.
To perform such optimizations, the code needs to be parsed to an AST, so concatenating strings only to then parse the strings is inefficient.

To avoid bugs due to typos in the generated code fragments, one can transform to an AST of the target language instead.
The AST is then transformed to code by a generated prettyprinter.
Additionally, it is easier to check correctness of an AST.
Stratego currently verifies the arity of constructors.
Verifying the arguments to a constructor are of the right type (e.g. checking that \inlinecode{x} and \inlinecode{y} in \inlinecode{Add(x, y)} are expressions instead of, say, import statements) is currently a work in progress.
Transforming to an AST also means that the transformed program is immediately ready for post-processing, no parsing required.

\subsubsection{Compilation with Stratego}
\label{subsubsec:problem_analysis__background__stratego}

Stratego is a meta-language to express program transformations.
Examples are optimizations \inlinecode{5 + x + 10 * x + 8} to \inlinecode{18 + 11 * x}) and compiling one language to another: \inlinecode{for (int i = 0; i<10; i++) \{...\}} to \inlinecode{for i in 0..9: ...}.
Stratego uses rules to define transformations from one constructor to another.
For example, the following rule combines two integer literals into a single value: \inlinecode{add-literal-ints: Plus(Int(x), Int(y)) -> Int(x + y)}.
There can be multiple rules with the same name.
Stratego will try them until one of them succeeds or all failed.
This is like an implicit pattern match against constructors:
\begin{lstlisting}
  fold-constants: And(True(), e2) -> e2
  fold-constants: And(False(), _) -> False()
  fold-constants: And(e1, True()) -> e1
  // No And(e1, False()) -> False() because that changes semantics, it won't execute e1 anymore
  fold-constants: If(True(), body_true, _) -> body_true
  fold-constants: If(False(), _, body_false) -> body_false
\end{lstlisting}

The \inlinecode{fold-constants} rule above will perform constant folding on booleans and if statements where the condition is a constant.
However, if we apply this rule to the term \inlinecode{If(And(True(), True()), Print("It's true"), Print("It's false"))}, it fails.
The \inlinecode{And} constructors don't match because the top level constructor is \inlinecode{If}.
And the \inlinecode{If} constructors don't match because the condition is neither \inlinecode{True()} nor \inlinecode{False()}, it is \inlinecode{And(...)}.

What we want instead, is to apply this rule to any matching subterm of the \ac{AST}.
To do this, Stratego has strategies.
A strategy defines how to apply a rule to an AST.
In this case, we can try to apply it to all subterms: \inlinecode{bottomup(try((fold-constants))}.
This first applies the rule to the subterms to produce \inlinecode{If(True(), Print("It's true"), Print("It's false"))}, and then apply the rule to the term itself to produce the final result \inlinecode{Print("It's true")}.

\subsubsection{Foreign functions in \ac{PIE} \ac{DSL}}
\label{subsubsec:problem_analysis__background__foreign_functions}

The \ac{PIE} \ac{DSL} can interoperate with Java by calling Java methods.
To call a Java method, it needs to be declared in the \ac{PIE} program.
A declaration looks like this:
\begin{lstlisting}
  func sign(x: int) -> int = foreign java java.lang.Math.signum
\end{lstlisting}
The part before the \inlinecode{=} is a normal \ac{PIE} function declaration.
It defines a function \inlinecode{sign} that takes an integer x and returns an integer.
The part after the \inlinecode{=} specifies the function definition.
\inlinecode{foreign java} designates this as a function that is declared in Java, and \inlinecode{java.lang.Math.signum} is the fully qualified name to the class and the function name.
The definition does not need the Java parameters because the \ac{PIE} parameters are mapped to Java parameters automatically.

\subsection{Problems}
\label{subsec:problem_analysis__problems}

\todo{Should I talk about these problems in the present tense or past tense? ("The PIE DSL cannot express ..." vs. "The PIE DSL could not express ...")}
The problems with the PIE DSL fall under two categories.
There are problems with the language design and problems with the language implementation.

\subsubsection{Lack of scalability}
\label{subsubsec:problem_analysis__problems__scalability}

A PIE program used to be written entirely in a single file, referring to other files was not possible.
In Spoofax, we want one PIE file per language project, PIE is limited to a single language project at a time.
In practice, compilers often need at least two language projects: a language project with the target language and a language project with the source language.
The compiler code itself is then either included in the source language or defined in a separate third language project.
Finally, a project could just consist of multiple projects.
An example is the Green-Marl compiler, which is one of the case studies (see \todo{add reference to Green-Marl pipelines case study}).
In conclusion, we want a principled way to refer to other PIE files in order to use PIE in bigger projects with multiple languages.

\subsubsection{Limitations in expressiveness}
\label{subsubsec:problem_analysis__problems__expressiveness}

The PIE framework is under active development.
This sometimes adds new requirements on things to express using the PIE DSL.

At the start of the thesis, the PIE framework used to throw exceptions to signal pipeline failure.
Checked exceptions in Java hurt composability of tasks, because checked exceptions from dependencies either need to be declared or caught.
Throwing exceptions to signal pipeline failure also has some semantic issues: exceptions are meant to signify an exceptional condition.
Malformed input is not unexpected, so this should not lead to an exception.
To solve this, the PIE framework switched to encoding the status of a task in its return value.
While a task can encode this in any way it likes, the standard way in PIE is to use the provided library class Result<T, E> that encodes either success with a normal value T or failure with an exception E.
These results are [composable]: a task can take a result and either do some computation if it has a value, or just pass along the exception if it had an exception.
This allows easy composition of tasks, where one only needs to check the final result for success or failure.
While this undoubtedly improves the PIE framework, it presents a problem for the PIE DSL: it now needs to support Result, and other generic library classes like Supplier<T>, Option<T>, <TODO: more examples?>.
The PIE DSL does not support generics.
Because foreign Java methods are declared in a PIE program with PIE DSL syntax, it is barely possible to interface with generic classes.
The only thing that can be declared is an instance of the generic parameter. That is not enough for classes that are used with different generic arguments, such as these library classes.
Additionally, it would be good if the PIE DSL could interoperate with arbitrary generic classes, not just generic classes from the \ac{PIE} library.

The other new requirement from the DSL stems from a property of tasks: not everything that is required to execute a task is an argument.
Sometimes values are hardcoded into the task\footnote{In the actual code these values are not hardcoded but added during \inlinecode{TaskDef} construction using dependency injection}.
An example is the StrategoRuntime that is used to execute Stratego strategies.
This runtime is specific to each language and is added to the task as an instance variable.
The PIE DSL did not have any way to specify such an instance variable.

We would like to extend the language with new syntax and semantics in order to handle these uses.

\subsubsection{NaBL2 limits static semantics}
\label{subsubsec:problem_analysis__problems__nabl2}

As mentioned in the previous problem, \todo{add reference} the PIE DSL could not interoperate with generic classes in Java.
The simplest solution is to add support for generic classes to PIE DSL as well.
However, PIE DSL is implemented using NaBL2.
NaBL2 does not have the power/expressiveness to allow implementing generics.
Furthermore, NaBL2 has limited static error reporting and limited ways to provide debugging information in case of runtime errors, which makes development in NaBL2 tedious.

\subsubsection{Compiler}
\label{subsubsec:problem_analysis__problems__compiler}

The PIE DSL had two compilers.
The first one compiled to Kotlin.
Kotlin is a language that gets compiled to bytecode for the JVM, which means that it can interoperate with Java and thus with the PIE framework.
Oracle didn't want to introduce Kotlin to their environment and asked us to compile directly to Java.

The second compiler compiled to Java using string interpolation.
Using string interpolation has several problems.
First of all, it is error-prone because the Stratego compiler cannot check that the string would form valid Java code, which means that typos don't get caught until Java compile time.
The second issue is that it is inefficient when you want to do post-processing on the generated Java code.
The generated Java string needs to be parsed before it can be used.
Instead of compiling to a string and then parsing that string to a Java AST, it is more efficient to compile directly to a Java AST.
Compiling to an AST also somewhat solves the first issue.
The Stratego compiler can catch typos in constructor names, but it does not check that the generated AST is a valid Java AST.

All this leads to two requirements for the compiler: it needs to compile to something that is already used in the Spoofax ecosystem (i.e. Java or bytecode) and it needs to compile to an AST.

