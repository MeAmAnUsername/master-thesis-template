\chapter{Evaluation}
\label{chap:evaluation}

The goal of the \ac{PIE} \ac{DSL} is to reduce boilerplate and bugs.
It should do this without sacrificing runtime performance or build time performance.
From a design perspective, the \ac{PIE} \ac{DSL} should cover future use cases as much as possible, or be extendable so that new language features could be added to cover unforeseen use cases.
This chapter evaluates whether the \ac{PIE} \ac{DSL} met these goals by applying it to three case studies and possibly some performance testing.

The first case study uses Tiger, which is a small functional language.
This gives a clean example of how the PIE DSL can be used to parse, analyze and compile a Spoofax language.

The second case study applies the \ac{PIE} \ac{DSL} to database pipelines.
Explaining what that means would just be a copy of the introduction for that section, so I'll just shut up now.

The last case study uses the \ac{PIE} \ac{DSL} to test language frontends at Oracle.
These language frontends only define the syntax for a language, and are meant as compilation targets for PGX.
As a sanity check, we would like to do reparse tests: parse an example program, pretty-print it, reparse the output of pretty-printing.
This should lead to the same AST.

The last section of this chapter provides an analysis of the results.
It looks at the main goals of reducing boilerplate and performance.
It also discusses the objectives of the generality and extensibility of the language itself.


\section{Case study: Tiger}
\label{sec:evaluation__tiger}

Tiger is a small functional language introduced in \textcite{Appel1998}.\footnote{A language reference manual can be found at \url{http://www.cs.columbia.edu/~sedwards/classes/2002/w4115/tiger.pdf}. The Spoofax language specification can be found on Github: \url{https://github.com/MetaBorgCube/metaborg-tiger/tree/master/org.metaborg.lang.tiger}}
It is used here as a clean example to apply \ac{PIE}.

The goal in this use case is to run some sort of transformation.\todo{what kind of transformation? (optimization: merge integers: 1 + 2 ==> 3)}
\todo{Add example code showing input and output of transformation}
This requires parsing and analyzing the tiger program, running the transformation, pretty-printing the transformed program to a string, and finally writing the string to a file.

\subsection{Pipeline implementation}
\label{subsec:evaluation__tiger__implementation}

Figure \ref{lst:case_study_tiger_pie} shows the \ac{PIE} \ac{DSL} code for this case study.
\Ac{PIE} tasks for parsing and analyzing are generated by Spoofax when building the language project.
Writing to a file is a task in the \ac{PIE} standard library.
All that is left is writing a task that invokes the transformation and wiring everything up.

\begin{figure}
  \caption{\Ac{PIE} \ac{DSL} code for the tiger case study}
  \label{lst:case_study_tiger_pie}
  \todo{Replace with actual code}
  \begin{lstlisting}
    module tiger:optimize

    import std:writeToFile
    import mb:metaborg:spoofax3:{IStrategoTerm, invokeStrategoStrategy as invoke}

    func parse(program: supplier<string>) -> IStrategoTerm = foreign mb:metaborg:example:tiger:Parse
    func analyze(ast: IStrategoTerm) -> (AnalysisResult) = foreign mb:metaborg:example:tiger:Analyze
    func prettyprint(ast: IStrategoTerm) -> string = foreign mb:metaborg:example:tiger:PrettyPrint

    // reads a tiger file, optimizes it, and writes the result back to the same file.
    func main(file: path) -> path = {
      val ast = read file;
      val analysisResult = analyze(ast);
      val optimized = optimize(ast, analysisResult);
      writeToFile(file, prettyprint(optimized));
    }

    func optimize(ast: IStrategoTerm, analysis: AnalysisResult) -> IStrategoTerm = invoke("tiger-optimize-all")
  \end{lstlisting}
\end{figure}

\todo{Add code that is used to call the thing}

\subsection{Analysis}
\label{sec:evaluation__tiger__analysis}

\begin{figure}
  \caption{Java code equivalent to the pie code in \ref{lst:case_study_tiger_pie}.}
  \label{lst:case_study_tiger_java}
  \question{Put this here or add it as appendix?}
  \todo{Add Java code}
\end{figure}

The equivalent Java code is given in figure \ref{lst:case_study_tiger_java}.
The \ac{PIE} \ac{DSL} code uses X \ac{loc}, while the equivalent Java code uses Y \ac{loc}.
\todo{Fill in actual numbers}

\section{Case study: PGX Algorithms pipelines}
\label{sec:evaluation__database}

\begin{figure}
  \caption{An implementation of the Adamic-Adar index in Green-Marl and \ac{PGX-A}}
  \label{lst:case_study_pgx_a_adamic_adar}
  \lstinputlisting[language=Java]{code/adamic-agar.java}
  \lstinputlisting{code/adamic-agar.gm}
\end{figure}

\Ac{PGX} is a toolkit for graph analysis, both for graph algorithms and SQL-like queries.
It provides two \acp{DSL}, Green-Marl and \ac{PGX-A}.
Both can express graph algorithms.
Green-Marl is a standalone \ac{DSL} for expressing graph algorithms.
\Ac{PGX-A} is an \ac{EDSL} in Java, this makes integration with Java easier.
Examples of graph algorithms are Dijkstra's algorithm for finding the shortest path\missingref and Kruskal's algorithm for finding the minimum spanning tree\missingref.
Another example is the Adamic-Adar index of edges.
Its implementation in Green-Marl and \ac{PGX-A} can be seen in figure \ref{lst:case_study_pgx_a_adamic_adar}.
The Adamic-Adar index can be used to predict edges between nodes in a social network.
\Ac{DFS} and \ac{BFS} are considered such fundamental algorithms that they are built-in functions.
The algorithms expressed in \ac{PGX-A} are compiled to an implementation for either a single machine or shared memory \ac{PGX} runtime.



The compilation goes as follows:
\begin{enumerate}
  \item The Java code is parsed and analyzed with a Spoofax definition of Java
  \item The Java code is transformed to Green-Marl.
  \item The Green-Marl is analyzed.
  \item The Green-Marl is compiled to C, C++, Java or \ac{PL/SQL} depending on what the runtime requires.
\end{enumerate}

This section
- [done] Explain Green-Marl and PGX-A
- [done] Add example code for both
- Explain goal of this section: pipeline for PGX-A, executable as command line tool
- Give results: PIE code, equivalent Java code, supporting code (Gradle, Java classes that can't be expressed in PIE, etc)

\subsection{Introduction}
\label{sec:evaluation__database__introduction}
\todo{What are Green-Marl, PGX?}
What are we trying to do in this case study?
-> Transform programs in some language to other languages.
\\
Interesting feature: multiple language projects and backends in separate projects.

\todo{write section}

\subsection{Pipeline implementation}
\label{sec:evaluation__database__implementation}

\todo{describe implementation}

\subsection{Analysis}
\label{sec:evaluation__database__analysis}

\todo{analysis}
\todo{should include part about multiple language projects}

\section{Case study: testing pipelines}
\label{sec:evaluation__testing}

\subsection{Introduction}
\label{sec:evaluation__testing__introduction}
What are we trying to do in this case study?
-> Execute Parse and reparse tests (check that parsing and reparsing example programs works)

\todo{write section}

\subsection{Pipeline implementation}
\label{sec:evaluation__testing__implementation}

\todo{describe implementation}

\subsection{Analysis}
\label{sec:evaluation__testing__analysis}

\todo{analysis}

\section{Analysis}
\label{sec:evaluation__analysis}

Note: some/most/all of this probably needs to go to the introduction or problem analysis.
It is currently here because I had to write it somewhere and I can't really make a good structure before I know what my goals and methodologies are.

\subsection{User goal and tasks}
Note: the user refers to the pipeline developer.\\
User use case: user needs to build some system and would like it to be precise, sound, incremental, etc.
The user has decided to use PIE to implement this pipeline.
We distinguish five categories of tasks related to writing pipeline code:
\begin{enumerate}
  \item Implementing the initial pipeline.
  The user either has no pipeline at all or has an existing pipeline in some other language or framework but decided to change to PIE.
  \item Changing or extending an existing pipeline.
  This refers to semantic changes to the pipeline: some pipeline steps need to be executed earlier, later, added or removed.
  \item Maintaining an existing pipeline.
  This refers to changes to the code that do not change the conceptual pipeline.
  For example, there was a change in the api of a dependency, so now the pipeline code needs to be updated to the new api.
  \item Reading the pipeline code to understand what it does, with no intention of changing it.
  This will happen a lot, definitely the most if we include reading of code during the other user tasks.
  If you want to change the pipeline in some way, you will likely need to read parts of it that do not need to be changed.
  \item Debugging the pipeline.
  This is not a goal by itself, but arises as part of the other tasks.
  It is mentioned explicitly because it is important: being unable to properly debug the pipeline (even with just print statements) severely harms the user friendliness.
\end{enumerate}

\subsection{Ultimate goals of the PIE DSL and this thesis}
Goal of the PIE DSL: make developing in PIE more user friendly by making it easier to write tasks.
Goals of this thesis: extend / improve the PIE DSL system and verify that the changes did indeed make it easier to write tasks.
We divide this into the following subgoals:
\begin{enumerate}
  \item Increase readability.
  Readability is a nebulous concept, but it more or less means that we want to convey the necessary information/understanding in an as short a time as possible.
  "Necessary information" refers to the information that the user requires for their particular task.
  Note that this does not mean that we optimize for shorter code.
  Shorter code is only useful if it allows the user to read the code faster.
  Reading the code happens in all user tasks, and is central to task 4: ``reading the pipeline code to understand it''.
  \item Increase the ease of writing.
  It should be easy and quick to write PIE DSL code.
  This can be achieved by making it specific to the domain of pipelines, by including types that are relevant to pipelines and by making common patterns easy to express.
  This is related to readability: if it is easy to read, it is likely not too long or complicated, so it would be easy to write as well.
  \item Make it easy to reason about.
  This is the step between reading and writing when making a change: once the user has read the code and understands what it does, it should be easy to reason about so that it is easy to figure out what to do to make the desired changes.
  The model of the framework is quite elegant, so we use it for the DSL as well.
  This makes it easier for users if they need to implement something in Java directly if the task they need cannot be expressed in the DSL.
  It also makes it easier to keep feature parity between the DSL and framework.
  Because we closely follow the PIE model and that is completely (mostly?) done, this thesis does not provide major contributions to the model.
\end{enumerate}


Afterthought: I think of it like this:
\begin{itemize}
  \item readability: how easy is it to read some fragment (e.g. a single task) of code and understand what it does?
  \item reasoning about it: once you understand what each fragment of code does, how easy is it to figure out what the pipeline as a whole does?
  How easy is it to figure out what changes should be made to bring about some desired change in behavior?
  How easy is it to break up an understanding of what the pipeline should do into fragments?
  \item Writing: once you understand what fragments there should be and how the fragments should compose to do what you want, how easy is it to write down these fragments as code or to modify the existing fragments?
\end{itemize}

Reasoning about the pipeline is mostly influenced by the model defined by PIE.
The reading and writing are where the DSL should bring improvements.

\subsection{Measurable goals for this thesis}
Our direct goals for the DSL are impossible to measure directly because they depend on the user.
There are however instrumental goals that improve usability:
\begin{enumerate}
  \item Increase the average amount of information that is visible on the screen (while keeping the readability of that information the same).
  We optimize for the amount of code visible on the screen, instead of the code that is contained within a line, because ultimately, the user reads the code from the screen.
  Many languages have boilerplate in the form of imports.
  Users often don't need to look at the imports to understand the code, so we don't care how much information is in those lines.
  We wouldn't care about the amount of lines imports take at all if it wouldn't take longer for users to scroll down to the code.
  (idea: put imports at the bottom of the file?)
  \item Reduce the amount of duplicate expressions of information.
  A duplicate expression of information is two or more places that express the same information.
  Duplicate expressions of information are bad because they need to be kept in sync: if the information changes, all expressions of it need to change as well.
  Duplicate expressions of information include code duplication, which expresses the same logic multiple times, but there other ways information can be expressed multiple times as well.
  A good example are PIE TaskDef identifiers.
  These are used to identify a task to the PIE framework.
  In regular \id{TaskDef}s, these are always \inlinecode{getClass().getName()}, which returns the fully qualified name of the class.
  The obvious duplicate expression of information here is the duplicate code, which expresses the logic that all these classes use their qualified class name as their ID.
  However, even when class IDs are written out by hand, like \inlinecode{mb.tiger.spoofax.task.TigerShowParsedAst}, it still is a duplicate expression of the information "this class is named \id{TigerShowParsedAst} and is located in package \inlinecode{mb.tiger.spoofax.task}", which is also already defined by the folder structure and file name \emph{and} the package statement and class name.
  Writing out the fully qualified ID explicitly duplicates the qualified name, but it also implicitly duplicated the logic that classes use their qualified name implicitly.
  Using the expression \inlinecode{getClass().getName()} expresses that logic explicitly, and avoids duplicating the qualified class name.
  Java unfortunately does not allow us to de-duplicate the logic, but this logic is expressed only once in the DSL and the user does not even need to know that task definitions have IDs.
  \item Increase editor services like static error reporting, showing documentation, automated imports and reference following.
  PIE DSL compared to pure Java actually does the opposite: no documentation, no static checks and no following references from Java to PIE or vice versa. There is however more static error reporting when comparing the old DSL to the new DSL.
  \item Increase expressiveness to increase applicability.
  Writing several tasks or helper functions and wrappers in Java does not improve user friendliness.
  Our main goal is to make it possible to express tasks at all, not necessarily to express things in multiple ways.
  \item Increase applicability to various domains. PIE can't be user friendly if it doesn't work for your domain.
\end{enumerate}

To evaluate whether the new PIE DSL meets these goals, we use the PIE DSL to express pipelines in various domains:
\begin{itemize}
  \item Spoofax 3 language compiler pipeline.
  Compiles a language specification to a language implementation.
  \item PGX-A program pipeline.
  Compiles a program from Green-Marl to C, C++, PL/SQL.
  \item Code editor/IDE for Tiger.
  Various tasks for editor actions.
  \item Testing pipeline.
  A pipeline for testing the generated parser and prettyprinter of a language.
  \item Benchmarking.
  Benchmarking pipelines for various things. We only want to re-execute the benchmarks for elements that were changed.
\end{itemize}

These case studies will be evaluated on the following points:
\begin{enumerate}
  \item Lines of code.
  We express each pipeline in the old DSL, the new DSL and Java.
  Because we express the exact same pipeline in all these languages, they each contain the same total amount of information.
  This means that we can use the lines of code to compare the amount of information per line in each language.
  This covers the amount of information that is visible on screen (sort of).
  \item The amount of information that is duplicated. \todo{How to test this? Seems like it should either be a theoretical analysis (like editor services below) or approximated using lines of code}
  \item The percentage of tasks that can be expressed in the DSL.
  This covers the expressiveness of the DSL.
  We will also compare this percentage between case studies to gauge how applicable the PIE DSL is across domains.
  \item Performance of the PIE tasks.
  While we don't require that the generated code is as fast as handwritten code, it should not be more than half a second / a factor 3 slower (whichever is higher).
  \item Build time of the pipeline.
  This is less important than the runtime, but having to wait a long time to test a pipeline is really annoying.
  Will be tested for both a clean build and with changes in a single task (incremental build).
\end{enumerate}

We will also perform some evaluations outside the case studies.
\begin{enumerate}
  \item New language features and the problems they solve.
  This will just be a discussion of the problems with the old DSL and how this was resolved in the new DSL.
  \item Editor services will be analyzed from a theoretical perspective.
  This is not done as part of the case studies because this concerns dynamic errors during development, and I really do not feel like writing down every time I get a static error or follow a reference.
  \item The time to write tasks is an important factor for the user friendliness, but is again something that cannot be tested with a completed pipeline.
  It is also hard to test objectively because experience from the other languages will likely improve the time of the last language.
  Instead, we will take some tasks that have already been implemented, read them, remove them (and the dependencies which are not used by other tasks), and then write them again to see how long that takes.
\end{enumerate}


\subsection{Boilerplate reduction}
\label{subsec:evaluation__analysis__boilerplate_reduction}

The conciseness of a language depends on two things: the information redundancy and code density.
The information redundancy is a measure of how much information is repeated within a program.
For example, in the Java statement \inlinecode{int x = 5;}, the type \id{int} is redundant, as it can already be derived from the expression.
Redundancy should not be minimized entirely, because redundant information can serve to make programs more understandable and to make error checking easier.
An example are function signatures.
Often, the signature of a function can be derived from its body, but that takes time and may require very complex analysis.
Having the type signature as part of the function signature allows developers and editors to get the type of a function without analyzing or even reading the function body.
In conclusion: information redundancy should be balanced with understandability and analyzability of the code.

\Ac{loc} only captures the vertical length of a program.
There is also the horizontal length, i.e. line length.
Long lines take longer to read than short lines [citation needed].


Goal: compare both information density (how much information is put into a given amount of code) and code density (physical amount of code on screen).

While \ac{loc} is not a metric that should be optimized when writing a program, it is useful to compare boilerplate of languages.
For the number of characters, sequences of layout are counted as a single character, i.e. in the following example, the whitespace from `\{' to `p' is counted as a single character.
\begin{lstlisting}
    Class Foo {
      private final int someNumber;
\end{lstlisting}


\begin{table}
  \caption{Lines of code, number of characters and their ratios between \ac{PIE} \ac{DSL} code and the equivalent Java code.}
  \label{tbl:evaluation_analysis_loc}
  \begin{tabular}{|r||l|l|l||l|l|l|}
    \hline
    & \multicolumn{3}{|c||}{Lines of code} & \multicolumn{3}{|c|}{Number of characters} \\
    \hline
    Case study & Java & \ac{PIE} \ac{DSL} & ratio (\%) & Java & \ac{PIE} \ac{DSL} & ratio (\%) \\
    \hline
    \hline
    Tiger & A & B & $C = B / A * 100\%$ & U & V & $V / U * 100\%$ \\
    Database & D & E & $F = E / D * 100\%$ & W & X & $X / W * 100\%$ \\
    Testing & G & H & $I = H / G * 100\%$ & Y & Z & $Z / Y * 100\%$ \\
    \hline
    Average & - & - & $(C + F + I)\%$ & - & - & ... \\
    \hline
  \end{tabular}
\end{table}

The lines of code and number of characters for each case study are summarized in table \ref{tbl:evaluation_analysis_loc}.
In each case study, the ratio of lines of code is below SomeNumber (where SomeNumber should be at most 50\% or I have to check this text again), but I expect it to be around 25\%), and the ratio of characters is around SomeOtherNumber (at most 40\%, expected 25\%).
This discrepancy is due to overhead from having multiple files and actual Java boilerplate.
Because each task needs to be a separate class and classes in Java are typically written one per file, we use two files to express the tasks that were not generated by Spoofax.
This duplicates the package statement and some of the imports.

The \id{exec} method contains almost all necessary information about the task.
The exception is the parameters in case there are more than one, these are defined in the \id{Input} class.
\todo{There also injected values that are not inputs for the task, but probably shouldn't mention them here}
The boilerplate comes from elements that repeat information. These elements are:
\begin{enumerate}
  \item The class declaration repeats the class input and output type, and specifies that this is a \ac{PIE} task.
  \item The \id{Input} class specifies the parameters and their types, but then repeats them in the constructor (twice), the \id{equals}, \id{hashcode} and \id{toString} methods.
  \item The fields and the constructor repeat the dependencies on other tasks (three times)
  \item \id{getId} gives a unique identifier for the task.
  This can be derived from the task name.
\end{enumerate}

\subsection{Non-functional requirements}
\label{subsec:evaluation__analysis__non_functional_requirements}

\todo{discuss non-functional requirements}
