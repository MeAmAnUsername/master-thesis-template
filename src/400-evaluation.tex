\chapter{Evaluation}
\label{chap:evaluation}

The goal of the \ac{PIE} \ac{DSL} is to reduce boilerplate and bugs.
It should do this without sacrificing runtime performance or build time performance.
From a design perspective, the \ac{PIE} \ac{DSL} should cover future use cases as much as possible, or be extendable so that new language features could be added to cover unforeseen use cases.
This chapter evaluates whether the \ac{PIE} \ac{DSL} met these goals by applying it to three case studies and possibly some performance testing.

The first case study uses Tiger, which is a small functional language.
This gives a clean example of how the PIE DSL can be used to parse, analyze and compile a Spoofax language.

The second case study applies the \ac{PIE} \ac{DSL} to database pipelines.
Explaining what that means would just be a copy of the introduction for that section, so I'll just shut up now.

The last case study uses the \ac{PIE} \ac{DSL} to test language frontends at Oracle.
These language frontends only define the syntax for a language, and are meant as compilation targets for PGX.
As a sanity check, we would like to do reparse tests: parse an example program, pretty-print it, reparse the output of pretty-printing.
This should lead to the same AST.

For each case study we compare the \ac{loc} and the number of characters of the \ac{PIE} \ac{DSL} code to the equivalent Java code.
While \ac{loc} is not a metric that should be optimized when writing a program, it is useful to compare boilerplate of languages.
For the number of characters, sequences of layout are counted as a single character, i.e. in the following example, the whitespace from `\{' to `p' is counted as a single character.
\begin{lstlisting}
    Class Foo {
      private final int someNumber;
\end{lstlisting}

The last section of this chapter provides an analysis of the results.
It looks at the main goal of reducing boilerplate and performance
It also discusses the objectives of the generality and extensibility of the language itself.


\section{Case study: Tiger}
\label{sec:evaluation__tiger}

Tiger is a small functional language introduced in \textcite{Appel1998}.\footnote{A language reference manual can be found at \url{http://www.cs.columbia.edu/~sedwards/classes/2002/w4115/tiger.pdf}. The Spoofax language specification can be found on Github: \url{https://github.com/MetaBorgCube/metaborg-tiger/tree/master/org.metaborg.lang.tiger}}
It is used here as a clean example to apply \ac{PIE}.

The goal in this use case is to run some sort of transformation.\todo{what kind of transformation? (optimization: merge integers: 1 + 2 ==> 3)}
\todo{Add example code showing input and output of transformation}
This requires parsing and analyzing the tiger program, running the transformation, pretty-printing the transformed program to a string, and finally writing the string to a file.

\subsection{Pipeline implementation}
\label{subsec:evaluation__tiger__implementation}

Figure \ref{lst:case_study_tiger_pie} shows the \ac{PIE} \ac{DSL} code for this case study.
\Ac{PIE} tasks for parsing and analyzing are generated by Spoofax when building the language project.
Writing to a file is a task in the \ac{PIE} standard library.
All that is left is writing a task that invokes the transformation and wiring everything up.

\begin{figure}
  \caption{\Ac{PIE} \ac{DSL} code for the tiger case study}
  \label{lst:case_study_tiger_pie}
  \todo{Replace with actual code}
  \begin{lstlisting}
    module tiger:optimize

    import std:writeToFile
    import mb:metaborg:spoofax3:{IStrategoTerm, invokeStrategoStrategy as invoke}

    func parse(program: supplier<string>) -> IStrategoTerm = foreign mb:metaborg:example:tiger:Parse
    func analyze(ast: IStrategoTerm) -> (AnalysisResult) = foreign mb:metaborg:example:tiger:Analyze
    func prettyprint(ast: IStrategoTerm) -> string = foreign mb:metaborg:example:tiger:PrettyPrint

    // reads a tiger file, optimizes it, and writes the result back to the same file.
    func main(file: path) -> path = {
      val ast = read file;
      val analysisResult = analyze(ast);
      val optimized = optimize(ast, analysisResult);
      writeToFile(file, prettyprint(optimized));
    }

    func optimize(ast: IStrategoTerm, analysis: AnalysisResult) -> IStrategoTerm = invoke("tiger-optimize-all")
  \end{lstlisting}
\end{figure}

\todo{Add code that is used to call the thing}

\subsection{Analysis}
\label{sec:evaluation__tiger__analysis}

\begin{figure}
  \caption{Java code equivalent to the pie code in \ref{lst:case_study_tiger_pie}.}
  \label{lst:case_study_tiger_java}
  \question{Put this here or add it as appendix?}
  \todo{Add Java code}
\end{figure}

The equivalent Java code is given in figure \ref{lst:case_study_tiger_pie}.
The \ac{PIE} \ac{DSL} code uses X \ac{loc}, while the equivalent Java code uses Y \ac{loc}.
\todo{Fill in actual numbers}

\todo{Move this analysis to overall analysis at the end of the chapter?}
This discrepancy is due to overhead from having multiple files and actual Java boilerplate.
Because each task needs to be a separate class and classes in Java are typically written one per file, we use two files to express the tasks that were not generated by Spoofax.
This duplicates the package statement and some of the imports.

The \id{exec} method contains almost all necessary information about the task.
The exception is the parameters in case there are more than one, these are defined in the \id{Input} class.
\todo{There also injected values that are not inputs for the task, but probably shouldn't mention them here}
The boilerplate comes from elements that repeat information. These elements are:
\begin{enumerate}
  \item The class declaration repeats the class input and output type, and specifies that this is a \ac{PIE} task.
  \item The \id{Input} class specifies the parameters and their types, but then repeats them in the constructor (twice), the \id{equals}, \id{hashcode} and \id{toString} methods.
  \item The fields and the constructor repeat the dependencies on other tasks (three times)
  \item \id{getId} gives a unique identifier for the task.
  This can be derived from the task name.
\end{enumerate}


\section{Case study: database pipelines}
\label{sec:evaluation__database}

\subsection{Introduction}
\label{sec:evaluation__database__introduction}
\todo{What are Green-Marl, PGX?}
What are we trying to do in this case study?
-> Transform programs in some language to other languages.
\\
Interesting feature: multiple language projects and backends in separate projects.

\todo{write section}

\subsection{Pipeline implementation}
\label{sec:evaluation__database__implementation}

\todo{describe implementation}

\subsection{Analysis}
\label{sec:evaluation__database__analysis}

\todo{analysis}
\todo{should include part about multiple language projects}

\section{Case study: testing pipelines}
\label{sec:evaluation__testing}

\subsection{Introduction}
\label{sec:evaluation__testing__introduction}
What are we trying to do in this case study?
-> Execute Parse and reparse tests (check that parsing and reparsing example programs works)

\todo{write section}

\subsection{Pipeline implementation}
\label{sec:evaluation__testing__implementation}

\todo{describe implementation}

\subsection{Analysis}
\label{sec:evaluation__testing__analysis}

\todo{analysis}

\section{Analysis}
\label{sec:evaluation__analysis}


\subsection{Boilerplate reduction}
\label{subsec:evaluation__analysis__boilerplate_reduction}

\begin{table}
  \caption{Lines of code, number of characters and their ratios between \ac{PIE} \ac{DSL} code and the equivalent Java code.}
  \label{tbl:evaluation_analysis_loc}
  \begin{tabular}{|r||l|l|l||l|l|l|}
    \hline
    & \multicolumn{3}{|c||}{Lines of code} & \multicolumn{3}{|c|}{Number of characters} \\
    \hline
    Case study & Java & \ac{PIE} \ac{DSL} & ratio (\%) & Java & \ac{PIE} \ac{DSL} & ratio (\%) \\
    \hline
    \hline
    Tiger & A & B & $C = B / A * 100\%$ & U & V & $V / U * 100\%$ \\
    Database & D & E & $F = E / D * 100\%$ & W & X & $X / W * 100\%$ \\
    Testing & G & H & $I = H / G * 100\%$ & Y & Z & $Z / Y * 100\%$ \\
    \hline
    Average & - & - & $(C + F + I)\%$ & - & - & ... \\
    \hline
  \end{tabular}
\end{table}
The lines of code and number of characters for each case study are summarized in 

\subsection{Non-functional requirements}
\label{subsec:evaluation__analysis__non_functional_requirements}

\todo{discuss non-functional requirements}
