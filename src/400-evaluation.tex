\chapter{Evaluation}
\label{chap:evaluation}

The goal of the \ac{PIE} \ac{DSL} is to reduce boilerplate and bugs.
It should do this without sacrificing runtime performance or build time performance.
From a design perspective, the \ac{PIE} \ac{DSL} should cover future use cases as much as possible, or be extendable so that new language features could be added to cover unforeseen use cases.
This chapter evaluates whether the \ac{PIE} \ac{DSL} met these goals by applying it to three case studies and possibly some performance testing.

The first case study uses Tiger, which is a small functional language.
This gives a clean example of how the PIE DSL can be used to parse, analyze and compile a Spoofax language.

The second case study applies the \ac{PIE} \ac{DSL} to database pipelines.
Explaining what that means would just be a copy of the introduction for that section, so I'll just shut up now.

The last case study uses the \ac{PIE} \ac{DSL} to test language frontends at Oracle.
These language frontends only define the syntax for a language, and are meant as compilation targets for PGX.
As a sanity check, we would like to do reparse tests: parse an example program, pretty-print it, reparse the output of pretty-printing.
This should lead to the same AST.

The last section of this chapter provides an analysis of the results.
It looks at the main goals of reducing boilerplate and performance.
It also discusses the objectives of the generality and extensibility of the language itself.


\section{Case study: Tiger}
\label{sec:evaluation__tiger}

Tiger is a small functional language introduced in \textcite{Appel1998}.\footnote{A language reference manual can be found at \url{http://www.cs.columbia.edu/~sedwards/classes/2002/w4115/tiger.pdf}. The Spoofax language specification can be found on Github: \url{https://github.com/MetaBorgCube/metaborg-tiger/tree/master/org.metaborg.lang.tiger}}
It is used here as a clean example to apply \ac{PIE}.

The goal in this use case is to run some sort of transformation.\todo{what kind of transformation? (optimization: merge integers: 1 + 2 ==> 3)}
\todo{Add example code showing input and output of transformation}
This requires parsing and analyzing the tiger program, running the transformation, pretty-printing the transformed program to a string, and finally writing the string to a file.

\subsection{Pipeline implementation}
\label{subsec:evaluation__tiger__implementation}

Figure \ref{lst:case_study_tiger_pie} shows the \ac{PIE} \ac{DSL} code for this case study.
\Ac{PIE} tasks for parsing and analyzing are generated by Spoofax when building the language project.
Writing to a file is a task in the \ac{PIE} standard library.
All that is left is writing a task that invokes the transformation and wiring everything up.

\begin{figure}
  \caption{\Ac{PIE} \ac{DSL} code for the tiger case study}
  \label{lst:case_study_tiger_pie}
  \todo{Replace with actual code}
  \begin{lstlisting}
    module tiger:optimize

    import std:writeToFile
    import mb:metaborg:spoofax3:{IStrategoTerm, invokeStrategoStrategy as invoke}

    func parse(program: supplier<string>) -> IStrategoTerm = foreign mb:metaborg:example:tiger:Parse
    func analyze(ast: IStrategoTerm) -> (AnalysisResult) = foreign mb:metaborg:example:tiger:Analyze
    func prettyprint(ast: IStrategoTerm) -> string = foreign mb:metaborg:example:tiger:PrettyPrint

    // reads a tiger file, optimizes it, and writes the result back to the same file.
    func main(file: path) -> path = {
      val ast = read file;
      val analysisResult = analyze(ast);
      val optimized = optimize(ast, analysisResult);
      writeToFile(file, prettyprint(optimized));
    }

    func optimize(ast: IStrategoTerm, analysis: AnalysisResult) -> IStrategoTerm = invoke("tiger-optimize-all")
  \end{lstlisting}
\end{figure}

\todo{Add code that is used to call the thing}

\subsection{Analysis}
\label{sec:evaluation__tiger__analysis}

\begin{figure}
  \caption{Java code equivalent to the pie code in \ref{lst:case_study_tiger_pie}.}
  \label{lst:case_study_tiger_java}
  \question{Put this here or add it as appendix?}
  \todo{Add Java code}
\end{figure}

The equivalent Java code is given in figure \ref{lst:case_study_tiger_java}.
The \ac{PIE} \ac{DSL} code uses X \ac{loc}, while the equivalent Java code uses Y \ac{loc}.
\todo{Fill in actual numbers}

\section{Case study: PGX Algorithms pipelines}
\label{sec:evaluation__database}

\begin{figure}
  \caption{An implementation of the Adamic-Adar index in Green-Marl and \ac{PGX-A}}
  \label{lst:case_study_pgx_a_adamic_adar}
  \lstinputlisting[language=Java]{code/adamic-agar.java}
  \lstinputlisting{code/adamic-agar.gm}
\end{figure}

\Ac{PGX} is a toolkit for graph analysis, both for graph algorithms and SQL-like queries.
It provides two \acp{DSL}, Green-Marl and \ac{PGX-A}.
Both can express graph algorithms.
Green-Marl is a standalone \ac{DSL} for expressing graph algorithms.
\Ac{PGX-A} is an \ac{EDSL} in Java, this makes integration with Java easier.
Examples of graph algorithms are Dijkstra's algorithm for finding the shortest path\missingref and Kruskal's algorithm for finding the minimum spanning tree\missingref.
Another example is the Adamic-Adar index of edges.
Its implementation in Green-Marl and \ac{PGX-A} can be seen in figure \ref{lst:case_study_pgx_a_adamic_adar}.
The Adamic-Adar index can be used to predict edges between nodes in a social network.
\Ac{DFS} and \ac{BFS} are considered such fundamental algorithms that they are built-in functions.
The algorithms expressed in \ac{PGX-A} are compiled to an implementation for either a single machine or shared memory \ac{PGX} runtime.



The compilation goes as follows:
\begin{enumerate}
  \item The Java code is parsed and analyzed with a Spoofax definition of Java
  \item The Java code is transformed to Green-Marl.
  \item The Green-Marl is analyzed.
  \item The Green-Marl is compiled to C, C++, Java or \ac{PL/SQL} depending on what the runtime requires.
\end{enumerate}

This chapter:
- [done] Explain Green-Marl and PGX-A
- [done] Add example code for both
- Explain goal of this chapter: pipeline for PGX-A, executable as command line tool
- Give results: PIE code, equivalent Java code, supporting code (Gradle, Java classes that can't be expressed in PIE, etc)

\subsection{Introduction}
\label{sec:evaluation__database__introduction}
\todo{What are Green-Marl, PGX?}
What are we trying to do in this case study?
-> Transform programs in some language to other languages.
\\
Interesting feature: multiple language projects and backends in separate projects.

\todo{write section}

\subsection{Pipeline implementation}
\label{sec:evaluation__database__implementation}

\todo{describe implementation}

\subsection{Analysis}
\label{sec:evaluation__database__analysis}

\todo{analysis}
\todo{should include part about multiple language projects}

\section{Case study: testing pipelines}
\label{sec:evaluation__testing}

\subsection{Introduction}
\label{sec:evaluation__testing__introduction}
What are we trying to do in this case study?
-> Execute Parse and reparse tests (check that parsing and reparsing example programs works)

\todo{write section}

\subsection{Pipeline implementation}
\label{sec:evaluation__testing__implementation}

\todo{describe implementation}

\subsection{Analysis}
\label{sec:evaluation__testing__analysis}

\todo{analysis}

\section{Analysis}
\label{sec:evaluation__analysis}


\subsection{Boilerplate reduction}
\label{subsec:evaluation__analysis__boilerplate_reduction}

The conciseness of a language depends on two things: the information redundancy and code density.
The information redundancy is a measure of how much information is repeated within a program.
For example, in the Java statement \inlinecode{int x = 5;}, the type \id{int} is redundant, as it can already be derived from the expression.
Redundancy should not be minimized entirely, because redundant information can serve to make programs more understandable and to make error checking easier.
An example are function signatures.
Often, the signature of a function can be derived from its body, but that takes time and may require very complex analysis.
Having the type signature as part of the function signature allows developers and editors to get the type of a function without analyzing or even reading the function body.
In conclusion: information redundancy should be balanced with understandability and analyzability of the code.

\Ac{loc} only captures the vertical length of a program.
There is also the horizontal length, i.e. line length.
Long lines take longer to read than short lines [citation needed].


Goal: compare both information density (how much information is put into a given amount of code) and code density (physical amount of code on screen).

While \ac{loc} is not a metric that should be optimized when writing a program, it is useful to compare boilerplate of languages.
For the number of characters, sequences of layout are counted as a single character, i.e. in the following example, the whitespace from `\{' to `p' is counted as a single character.
\begin{lstlisting}
    Class Foo {
      private final int someNumber;
\end{lstlisting}


\begin{table}
  \caption{Lines of code, number of characters and their ratios between \ac{PIE} \ac{DSL} code and the equivalent Java code.}
  \label{tbl:evaluation_analysis_loc}
  \begin{tabular}{|r||l|l|l||l|l|l|}
    \hline
    & \multicolumn{3}{|c||}{Lines of code} & \multicolumn{3}{|c|}{Number of characters} \\
    \hline
    Case study & Java & \ac{PIE} \ac{DSL} & ratio (\%) & Java & \ac{PIE} \ac{DSL} & ratio (\%) \\
    \hline
    \hline
    Tiger & A & B & $C = B / A * 100\%$ & U & V & $V / U * 100\%$ \\
    Database & D & E & $F = E / D * 100\%$ & W & X & $X / W * 100\%$ \\
    Testing & G & H & $I = H / G * 100\%$ & Y & Z & $Z / Y * 100\%$ \\
    \hline
    Average & - & - & $(C + F + I)\%$ & - & - & ... \\
    \hline
  \end{tabular}
\end{table}

The lines of code and number of characters for each case study are summarized in table \ref{tbl:evaluation_analysis_loc}.
In each case study, the ratio of lines of code is below SomeNumber (where SomeNumber should be at most 50\% or I have to check this text again), but I expect it to be around 25\%), and the ratio of characters is around SomeOtherNumber (at most 40\%, expected 25\%).
This discrepancy is due to overhead from having multiple files and actual Java boilerplate.
Because each task needs to be a separate class and classes in Java are typically written one per file, we use two files to express the tasks that were not generated by Spoofax.
This duplicates the package statement and some of the imports.

The \id{exec} method contains almost all necessary information about the task.
The exception is the parameters in case there are more than one, these are defined in the \id{Input} class.
\todo{There also injected values that are not inputs for the task, but probably shouldn't mention them here}
The boilerplate comes from elements that repeat information. These elements are:
\begin{enumerate}
  \item The class declaration repeats the class input and output type, and specifies that this is a \ac{PIE} task.
  \item The \id{Input} class specifies the parameters and their types, but then repeats them in the constructor (twice), the \id{equals}, \id{hashcode} and \id{toString} methods.
  \item The fields and the constructor repeat the dependencies on other tasks (three times)
  \item \id{getId} gives a unique identifier for the task.
  This can be derived from the task name.
\end{enumerate}

\subsection{Non-functional requirements}
\label{subsec:evaluation__analysis__non_functional_requirements}

\todo{discuss non-functional requirements}
